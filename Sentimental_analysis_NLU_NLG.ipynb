{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentimental analysis NLU/NLG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxVtTPK0KLCd"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "\n",
        "from matplotlib import style,rcParams\n",
        "style.use('seaborn-white')\n",
        "rcParams['figure.figsize'] = 10,5\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report\n",
        "#from scikitplot.metrics import plot_confusion_matrix\n",
        "\n",
        "df_train = pd.read_csv(r\"/content/train.txt\",delimiter=';',names=['text','label'])\n",
        "df_val = pd.read_csv(\"/content/val.txt\",delimiter=';',names=['text','label'])\n",
        "\n",
        "df = pd.concat([df_train,df_val])\n",
        "\n",
        "print(\"Shape of the DataFrame:\",df.shape)\n",
        "\n",
        "\n",
        "df.reset_index(inplace=True,drop=True)\n",
        "\n",
        "df.head()\n",
        "sns.countplot(df.label)\n",
        "\n",
        "def custom_encoder(df):\n",
        "    df.replace(to_replace =\"surprise\", value =1, inplace=True)\n",
        "    df.replace(to_replace =\"love\", value =1, inplace=True)\n",
        "    df.replace(to_replace =\"joy\", value =1, inplace=True)\n",
        "    df.replace(to_replace =\"fear\", value =0, inplace=True)\n",
        "    df.replace(to_replace =\"anger\", value =0, inplace=True)\n",
        "    df.replace(to_replace =\"sadness\", value =0, inplace=True)\n",
        "    \n",
        "custom_encoder(df['label'])\n",
        "\n",
        "sns.countplot(df.label)\n",
        "df.head()\n",
        "#object of WordNetLemmatizer\n",
        "lm = WordNetLemmatizer()\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def text_transformation(df_col):\n",
        "    corpus = []\n",
        "    for item in df_col:\n",
        "        new_item = re.sub('[^a-zA-Z]',' ',str(item))\n",
        "        new_item = new_item.lower()\n",
        "        new_item = new_item.split()\n",
        "        new_item = [lm.lemmatize(word) for word in new_item if word not in set(stopwords.words('english'))]\n",
        "        corpus.append(' '.join(str(x) for x in new_item))\n",
        "    return corpus\n",
        "\n",
        "corpus = text_transformation(df['text'])\n",
        "rcParams['figure.figsize'] = 20,8\n",
        "word_cloud = \"\"\n",
        "for row in corpus:\n",
        "    for word in row:\n",
        "        word_cloud+=\" \".join(word)\n",
        "\n",
        "wordcloud = WordCloud(width = 1000, height = 500,background_color ='white',min_font_size = 10).generate(word_cloud)\n",
        "plt.imshow(wordcloud)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(ngram_range=(1,2))\n",
        "traindata = cv.fit_transform(corpus)\n",
        "\n",
        "X = traindata\n",
        "y = df.label\n",
        "\n",
        "parameters = {'max_features': ('auto','sqrt'),\n",
        "             'n_estimators': [500, 1000],\n",
        "             'max_depth': [10, None],\n",
        "             'min_samples_split': [5],\n",
        "             'min_samples_leaf': [1],\n",
        "             'bootstrap': [True]}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(),parameters,cv=5,return_train_score=True,n_jobs=-1)\n",
        "grid_search.fit(X,y)\n",
        "grid_search.best_params_\n",
        "\n",
        "\n",
        "for i in range(6):\n",
        "    print('Parameters: ',grid_search.cv_results_['params'][i])\n",
        "    print('Mean Test Score: ',grid_search.cv_results_['mean_test_score'][i])\n",
        "    print('Rank: ',grid_search.cv_results_['rank_test_score'][i])\n",
        "    \n",
        "\n",
        "rfc = RandomForestClassifier(max_features=grid_search.best_params_['max_features'],\n",
        "                                      max_depth=grid_search.best_params_['max_depth'],\n",
        "                                      n_estimators=grid_search.best_params_['n_estimators'],\n",
        "                                      min_samples_split=grid_search.best_params_['min_samples_split'],\n",
        "                                      min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
        "                                      bootstrap=grid_search.best_params_['bootstrap'])\n",
        "\n",
        "rfc.fit(X,y)\n",
        "test_df = pd.read_csv('test.txt',delimiter=';',names=['text','label'])\n",
        "rcParams['figure.figsize'] = 10,5\n",
        "plot_confusion_matrix(y_test,predictions)\n",
        "acc_score = accuracy_score(y_test,predictions)\n",
        "pre_score = precision_score(y_test,predictions)\n",
        "rec_score = recall_score(y_test,predictions)\n",
        "print('Accuracy_score: ',acc_score)\n",
        "print('Precision_score: ',pre_score)\n",
        "print('Recall_score: ',rec_score)\n",
        "print('-------------------------------------------------------------------')\n",
        "cr = classification_report(y_test,predictions)\n",
        "print(cr)\n",
        "predictions_probability = rfc.predict_proba(testdata)\n",
        "\n",
        "fpr,tpr,thresholds = roc_curve(y_test,predictions_probability[:,1])\n",
        "plt.plot(fpr,tpr)\n",
        "plt.plot([0,1])\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()\n",
        "\n",
        "def expression_check(prediction_input):\n",
        "    if prediction_input == 0:\n",
        "        print(\"Input statement has Negative Sentiment.\")\n",
        "    elif prediction_input == 1:\n",
        "        print(\"Input statement has Positive Sentiment.\")\n",
        "    else:\n",
        "        print(\"Invalid Statement.\")\n",
        "\n",
        "def sentiment_predictor(input):\n",
        "    input = text_transformation(input)\n",
        "    transformed_input = cv.transform(input)\n",
        "    prediction = rfc.predict(transformed_input)\n",
        "    expression_check(prediction)\n",
        "\n",
        "input1 = [\"i didnt feel humiliated.\"]\n",
        "input2 = [\"i am feeling grouchy.\"]\n",
        "sentiment_predictor(input1)\n",
        "sentiment_predictor(input2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}